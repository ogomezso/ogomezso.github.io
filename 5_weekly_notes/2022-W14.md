# 2022-04-04


##### status: #daily_note 

# Tasks

#todo 
- [x] Upload Draft Version of Test Utils
- [x] Document Clients of Test Utils

# Work Notes

# Meeting Notes
# 2022-04-04 10:05
##### status: #meeting_note
##### Tags:

### Client:
[[Santander]]

### Topic:
Daily

### Attendees:
* Miguel Angel 
* Abel Fernandez
* Jorge Quilcate
* Oscar Gomez

### Notes:

- Upgrade of Ksql in danger due the incident with GDO2 -> upgrade of ksql in risk they think the problem can be related to the new version 
-  Hive JDBC on the same status
- Certs upgraded in DEV -> some issue with ansible script solved running it again
---

# 2022-04-05


##### status: #daily_note 

# Work Notes


### 2022-04-05-17:02 Kafka Test Utils on Cilantrum

---

tags:
[[integration_test]]

---
### Notes

```ad-info
title: Configuration Properties for Kafka-test-utils



```

---



# Meeting Notes
# 2022-04-05 09:33
##### status: #meeting_note
##### Tags:

### Client:
[[Santander]]

### Topic:
Daily

### Attendees:
* Oscar Gómez
* Jorge Quilcate
* Abel Fernandez
* Miguel Angel García de la Cruz
* Ivan Yañez de la Rua

### Notes:

- KSQL negative lags, possible cause recreation of base topics
- Monitoring for KSQL upgraded

# 2022-04-05 17:26
##### status: #meeting_note
##### Tags:

### Client:
[[Santander]]

### Topic:
Test Funcionales

### Attendees:
* Jose Alberto Rollon
* Miguel Angel 
* Abel Fernandez

### Notes:

- April 29th to have the library integrated on the projects
- Demon/Talk on Test Automation Community
- Possibility of a "office hour" to work with the projects on their usecases
 #todo 
  - [ ] Integrate Library with Laika and Vostock -> Jose Alberto Rollon
  - [x] Integrate `kafka-test-utils` on Cylantrum Library -> Jose Alberto Rollon
  - [ ] Integrate `kafka-test-utils` on Cucumber Library -> Oscar Gómez
  - [ ] Provide Examples of testing (kafka-clients-benchmark???) -> Oscar Gómez
  - [ ] Perf Test with datagen
  - [x] File Reader

---

# 2022-04-06


##### status: #daily_note 

# Work Notes


### 2022-04-06-09:58 Kafka-Test-Utils

---

tags:
[[integration_test]]
team:
[[Santander]]

---

### Notes
```ad-note
title: Properties for kafka-test-utils Santander

security.protocol=SASL_SSL  
ssl.truststore.location=truststore.jks  
ssl.truststore.password=changeit  
sasl.mechanism=GSSAPI  
sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true serviceName=kafka keyTab="/opt/confluent/etc/aplcxm.keytab" principal="aplcxm@PREBCE.PRESAN.SANTANDER.CORP";  
sasl.kerberos.service.name=kafka

```

```ad-note
title: Config Constructor

New constructor added to take properties file from relative path.

```

[https://github.alm.europe.cloudcenter.corp/sanes-adn360/adn360-test-utilities](https://github.alm.europe.cloudcenter.corp/sanes-adn360/adn360-test-utilities "https://github.alm.europe.cloudcenter.corp/sanes-adn360/adn360-test-utilities")

---



### 2022-04-06-13:06 JDBC Hive Connector

---

tags:
[[kafka_connect]] [[hive]] [[jdcb_source_connector]]
team:
[[Santander]] [[Panoramix]]

---

### Notes

- Due limitations on hive JDBC Driver the use of licensed JDBC Connector is not possible so we need to develop a custom source connector
- The best approach for this brand new connector is taking JDBC as base use a new dialect `hiveDialect` and use the hadoop or hive client to do the authentication: https://docs.cloudera.com/HDPDocuments/HDP1/HDP-1.2.3/ds_Hive/hiveclient.html

---


# Meeting Notes

# 2022-04-06 09:49
##### status: #meeting_note
##### Tags:

### Client:
[[Santander]]

### Topic:
Daily

### Attendees:
* Ivan Yañez
* Miguel Angel
* Abel Fernandez
* Oscar Gómez

### Notes:

- **Connect Metrics Interceptors:** We are missing some metrics after on the interceptors. [[Jorge Quilcate]] 
- **KSQL GDO Inciden**t: KSQL Instance is running with half of resources, there is a request to increase it again and put to the level we have on previous version. And try again. They still thinking about a problem in the new KSQL version
- **JDBC Hive connector**: Still on the same page. They will be trying with the custom connector -> Oscar take a look of the code that Alejandro give to you
- **Functional Test** -> Help Jose Alberto Rollon to put his example to work. Provide example of use case (kafka-client-benchmark fork???)

# 2022-04-06 16:58
##### status: #meeting_note
##### Tags:

### Client:
[[Santander]]
### Topic:
Use of kafka test Utils
### Attendees:
* [[Jose Alberto Rollon]]
* [[Jose Manuel Pellejero]]
* Oscar Gomez
### Notes:

- They need a file reader
- key for separator
- need to pass environment as parameter to 
- Tomorrow new checkpoint to start the first test
---

# 2022-04-07



##### status: #daily_note 

# Work Notes

# Meeting Notes
# 2022-04-07 09:46
##### status: #meeting_note
##### Tags:

### Client:
[[Santander]]

### Topic:
Daily

### Attendees:
* Attendee
### Notes:

- **E2E for Dynatrace**: 
	- Custom Service on Dynatrace that intercepts the class and look the headers
	- What class we can intercept on all connectors
- **KSQL CPU Usage**:
	- From the upgrade we saw the process of KSQL on a constant use of 100% of cpu
	- Caso ID #100610
---

# 2022-04-08


##### status: #daily_note 

# Work Notes

# Meeting Notes
# 2022-04-08 10:32
##### status: #meeting_note
##### Tags:

### Client:
[[Allianz]]
### Topic:
### Attendees:
* Temuka
* Mathias
* Daniel Maganto
* Alfredo Gil
* Marcus Marcelo
* Oscar Gomez 
* Nakul Mishra

### Notes:

#### Spring Streams APP

- Auto offset set to `earliest` so the behaviour is the expected one
- Temuka and Mathias will take a look why the config is not there (they think they have it in place)

#### Performance Issue

- Spring app take 2 times to read all the data on CCloud than in MSK
- We are guessing latency issues
- Just experiment with perf test on both side to measure the differences
##### Producer
- MSK
~~~
168616 records sent, 33723.2 records/sec (1.61 MB/sec), 1656.1 ms avg latency, 2498.0 ms max latency.
750069 records sent, 150013.8 records/sec (7.15 MB/sec), 2973.9 ms avg latency, 4379.0 ms max latency.
1000000 records sent, 90859.531165 records/sec (4.33 MB/sec), 2824.81 ms avg latency, 4379.00 ms max latency, 2699 ms 50th, 4178 ms 95th, 4314 ms 99th, 4370 ms 99.9th.
~~~

 - CCLOUD
~~~
204000 records sent, 40800.0 records/sec (1.95 MB/sec), 1112.2 ms avg latency, 2109.0 ms max latency.
1000000 records sent, 117855.038303 records/sec (5.62 MB/sec), 1933.98 ms avg latency, 2407.00 ms max latency, 2108 ms 50th, 2320 ms 95th, 2380 ms 99th, 2402 ms 99.9th.
~~~

##### Consumer

~~~
I have no name!@kafka-cli-6f9b9bd5d6-d7ms9:/$ time /kafka/kafka_2.13-2.7.0/bin/kafka-consumer-perf-test.sh \
>   --broker-list b-1.kafka-prod.acpqqj.c2.kafka.eu-central-1.amazonaws.com:9094 \
>   --consumer.config /tmp/kafka.properties \
>   --topic marcus-test-1234 \
>   --messages 1000000 \
>   --group=marcus-perf-test2 \
>   --show-detailed-stats \
>   --timeout 60000
time, threadId, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec
2022-04-08 09:35:32:908, 0, 0.8822, 0.1755, 18501, 3680.3262, 1649410532017, -1649410526990, 0.0000, 0.0000

real	0m10.262s
user	0m6.659s
sys	0m0.519s
I have no name!@kafka-cli-6f9b9bd5d6-d7ms9:/$ time /kafka/kafka_2.13-2.7.0/bin/kafka-consumer-perf-test.sh \
>   --broker-list lkc-81zo80-e0895.eu-central-1.aws.glb.confluent.cloud:9092 \
>   --consumer.config /tmp/cccloud.properties \
>   --topic marcus-test-1234 \
>   --messages 1000000 \
>   --group=marcus-perf-test2 \
>   --show-detailed-stats \
>   --timeout 60000
time, threadId, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec

real	0m7.049s
user	0m6.252s
sys	0m0.474s

~~~


#### Spring boot APP

~~~
Apr 8, 2022 @ 11:55:57.486	Started MainSpringBootApplication in 150.495 seconds (JVM running for 153.072)
~~~

~~~

ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [b-1.kafka-prod.acpqqj.c2.kafka.eu-central-1.amazonaws.com:9094, b-2.kafka-prod.acpqqj.c2.kafka.eu-central-1.amazonaws.com:9094, b-3.kafka-prod.acpqqj.c2.kafka.eu-central-1.amazonaws.com:9094, b-4.kafka-prod.acpqqj.c2.kafka.eu-central-1.amazonaws.com:9094, b-5.kafka-prod.acpqqj.c2.kafka.eu-central-1.amazonaws.com:9094, b-6.kafka-prod.acpqqj.c2.kafka.eu-central-1.amazonaws.com:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-devops-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = devops-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = [com.allianz.direct.kafka.DefaultConsumerInterceptor]
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /etc/kafka/keystore.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = SSL
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	
~~~

#### CCLOUD

~~~
Started MainSpringBootApplication in 206.206 seconds (JVM running for 209.306)
~~~

~~~
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [lkc-81zo80-e0895.eu-central-1.aws.glb.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-devops-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = devops-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = [com.allianz.direct.kafka.DefaultConsumerInterceptor]
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandling
~~~
