##### status: #daily_note 

# Tasks

#todo 
- [x] Replicator Monitoring
- [x] Fresh Cluster Provision
- [x] Create Accounts and API Key
- [x] Create Replicator
- [x] Migrate Data
- [x] Migrate Producers
- [x] Migrate Consumers
- [x] Migrate Streams
- [ ] Migrate Connect
- [ ] Clean Up

# Work Notes

# Meeting Notes

# 2022-03-03 08:36
##### status: #meeting_note
##### Tags:

### Client:
[[Allianz]]

### Topic:
[[ccloud_migration]]

### Attendees:
* Nakul Mishra
* Oscar Gómez Soriano 
* Marcus Barcelos
### Notes:

--- 
### 08:42

### Status: #fleeting_note
### Tags: [[replicator_monitoring]]
### References

### Notes:

```ad-error

Scrapping fails on the scrap. We don't have the same metrics.

Just grab the rules from JMX examples and paste on the helm chart jmx-configmap.yaml

```

~~~
{{- if and .Values.prometheus.jmx.enabled }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ template "cp-kafka-connect.fullname" . }}-jmx-configmap
  labels:
    app: {{ template "cp-kafka-connect.name" . }}
    chart: {{ template "cp-kafka-connect.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  jmx-kafka-connect-prometheus.yml: |+
    jmxUrl: service:jmx:rmi:///jndi/[rmi://localhost](rmi://localhost):{{ .Values.jmx.port }}/jmxrmi
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    ssl: false
    whitelistObjectNames:
    - kafka.connect:type=app-info,client-id=*
    - kafka.connect:type=connect-worker-rebalance-metrics
    - kafka.connect:type=connect-coordinator-metrics,*
    - kafka.connect:type=connect-metrics,*
    - kafka.connect:type=connect-worker-metrics
    - kafka.connect:type=connect-worker-metrics,*
    - kafka.connect:type=connector-metrics,*
    - kafka.connect:type=*-task-metrics,*
    - kafka.connect:type=task-error-metrics,*
    - confluent.replicator:type=confluent-replicator-task-metrics,*
    - "kafka.consumer:*"
    - "kafka.producer:*"
    blacklistObjectNames:
    - "kafka.admin.client:*"
    - "kafka.consumer:type=*,id=*"
    - "kafka.producer:type=*,id=*"
    - "kafka.producer:client-id=confluent.monitoring*,*"
    - "kafka.*:type=kafka-metrics-count,*"
    rules:
      - pattern: "kafka.connect<type=app-info, client-id=(.+)><>(.+): (.+)"
        name: "kafka_connect_app_info"
        value: 1
        labels:
          client-id: "$1"
          $2: "$3"
        type: UNTYPED
      - pattern: "kafka.connect<type=connect-worker-rebalance-metrics><>([^:]+)"
        name: "kafka_connect_connect_worker_rebalance_metrics_$1"
      - pattern: "kafka.connect<type=(.+), client-id=(.+)><>([^:]+)"
        name: kafka_connect_$1_$3
        labels:
          client_id: $2
      - pattern: "kafka.connect<type=connect-worker-metrics><>([^:]+)"
        name: kafka_connect_connect_worker_metrics_$1
        labels:
          connector: "aggregate"
      - pattern: "kafka.connect<type=connect-worker-metrics, connector=(.+)><>([^:]+)"
        name: kafka_connect_connect_worker_metrics_$2
        labels:
          connector: $1
      - pattern: "kafka.connect<type=connector-metrics, connector=(.+)><>(.+): (.+)"
        value: 1
        name: kafka_connect_connector_metrics
        labels:
          connector: $1
          $2: $3
        type: UNTYPED
      - pattern: "kafka.connect<type=(.+)-task-metrics, connector=(.+), task=(\\d+)><>(.+): (.+)"
        name: kafka_connect_$1_task_metrics_$4
        labels:
          connector: "$2"
          task: "$3"
      - pattern: "kafka.connect<type=task-error-metrics, connector=(.+), task=(\\d+)><>([^:]+)"
        name: kafka_connect_task_error_metrics_$3
        labels:
          connector: "$1"
          task: "$2"
      - pattern: "confluent.replicator<type=confluent-replicator-task-metrics, confluent-replicator-(.*)=(.+), confluent-replicator-(.+)=(.+), confluent-replicator-(.+)=(.+), confluent-replicator-(.+)=(.+)><>confluent-replicator-task-topic-partition-(.*): (.*)"
        name: confluent_replicator_task_metrics_$9
        labels:
          $1: "$2"
          $3: "$4"
          $5: "$6"
          $7: "$8"
      - pattern: "confluent.replicator<type=confluent-replicator-task-metrics, confluent-replicator-(.*)=(.+), confluent-replicator-(.+)=(.+), confluent-replicator-(.+)=(.+), confluent-replicator-(.+)=(.+)><>(confluent-replicator-destination-cluster|confluent-replicator-source-cluster|confluent-replicator-destination-topic-name): (.*)"
        name: confluent_replicator_task_metrics_info
        value: 1
        labels:
          $1: "$2"
          $3: "$4"
          $5: "$6"
          $7: "$8"
          $9: "$10"
      # "kafka.consumer:type=app-info,client-id=*"
      # "kafka.producer:type=app-info,client-id=*"
      - pattern: "kafka.(.+)<type=app-info, client-id=(.+)><>(.+): (.+)"
        value: 1
        name: kafka_$1_app_info
        labels:
          client_type: $1
          client_id: $2
          $3: $4
        type: UNTYPED
      # "kafka.consumer:type=consumer-metrics,client-id=*, protocol=*, cipher=*"
      # "kafka.consumer:type=type=consumer-fetch-manager-metrics,client-id=*, topic=*, partition=*"
      # "kafka.producer:type=producer-metrics,client-id=*, protocol=*, cipher=*"
      - pattern: "kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+), (.+)=(.+)><>(.+):"
        name: kafka_$1_$2_$9
        type: GAUGE
        labels:
          client_type: $1
          $3: "$4"
          $5: "$6"
          $7: "$8"
      # "kafka.consumer:type=consumer-node-metrics,client-id=*, node-id=*"
      # "kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*, topic=*"
      # "kafka.producer:type=producer-node-metrics,client-id=*, node-id=*"
      # "kafka.producer:type=producer-topic-metrics,client-id=*, topic=*"
      - pattern: "kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+)><>(.+):"
        name: kafka_$1_$2_$7
        type: GAUGE
        labels:
          client_type: $1
          $3: "$4"
          $5: "$6"
      # "kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*"
      # "kafka.consumer:type=consumer-metrics,client-id=*"
      # "kafka.producer:type=producer-metrics,client-id=*"
      - pattern: "kafka.(.+)<type=(.+), (.+)=(.+)><>(.+):"
        name: kafka_$1_$2_$5
        type: GAUGE
        labels:
          client_type: $1
          $3: "$4"
      - pattern: "kafka.(.+)<type=(.+)><>(.+):"
        name: kafka_$1_$2_$3
        labels:
          client_type: $1
{{- end }}
~~~


---

--- 
### 10:19

### Status: #fleeting_note
### Tags:
[[replicator_monitoring]]
### References

### Notes:

```ad-success

after tweak dashboards and the scrape rules we have the monitoring in place

```

```ad-info

Go from the scratch with fresh cluster

```


Service Accounts are in place:

![[Pasted image 20220303102703.png]]
---

--- 
### 10:46

### Status: #fleeting_note
### Tags:
[[replicator_config]]

### References

### Notes:

```ad-error

Error when trying to delete the replicator connector.

seems to be a problem with the leader resolution with the rest advertised lister, we have 30 instances
```
```ad-error

{“error_code”:500,“message”:“Error trying to forward REST request: Error trying to forward REST request: Cannot complete request because of a conflicting operation (e.g. worker rebalance)“}

```

```ad-warning

The exception seems no to be ok, there is not rebalancing in process is matter of listeners

```



---
--- 
### 11:47

### Status: #fleeting_note
### Tags:
[[replicator_config]]
### References

### Notes:

```ad-success

scale down replicator to 1 and deletion succeed

```
```ad-error

When scale to 5 the problem again there

```
```ad-info
we figure out that the rest advertided host port config were missing that explain the timeout errors.

rebalance in take place. **it tooks 4min**.
```
```ad-warning

We found errors on the producer config on the replicator

we also found that in some point replication starts and we need to delete all the topics on CCLOUD

We also need to rename replicator just to start the replication from the very beginning

```

---


--- 
### 13:10

### Status: #fleeting_note
### Tags:
[[replicator_config]]
### References

### Notes:

```ad-note

We start to replicate

```

```ad-error

We are not able to replicate from the beginning because of a misconfiguration. They are overriding *src.consumer.groupid* so consumer group is not recreated even with a new connector name.
```

---
--- 
### 16:59

### Status: #fleeting_note
### Tags:
[[ccloud_migration]] 
### References

### Notes:

```ad-success

Replication finished:




```
![[image (1).png]]

![[image.png]]

Duplicates dissapeared:

![[Pasted image 20220303172606.png]]

Lag 0 at the end:

![[Pasted image 20220303172644.png]]

Many "garbage topics" with many many topics:

![[Pasted image 20220303172832.png]]



---

--- 
### 17:30

### Status: #fleeting_note
### Tags:
[[schema_registry]]

### References

### Notes:

```ad-warning

before stop Connect stop replicator

```

- [x] Schema Registry to READONLY
- [x] Schema local backup
- [x] Stop Apps
- [x] Point Schema Registry to CCloud
- [x] Start Test App
- [x] Start Apps (KStreams included)

```ad-error

The script that stop the cluster, stop connect to before pausing replicator.

So we figure out how to delete it beofre start

We decide to just delete the connect config topic and then recreate the connectors again

Allianz face some problems on the connect config.


```

```ad-info

sanity check for streams and connect tomorrow.

```

---
