##### status: #daily_note 

# Work Notes

# Meeting Notes
# 2022-05-05 09:39
##### status: #meeting_note
##### Tags:

### Client:
[[Santander]]
### Topic:
Daily
### Attendees:
* [[Abel]]
### Notes:

- Syslog connector to replace flume (5 agents).
	- Concerns:
		- Put in HA
		- Load Balancer not seems to be a option ("matar moscas a caÃ±onazos")
		- Need to meet Fernando Diaz Gallego to go deep on the use case.
- Julie Ops use case for next monday
- [[Kafka Test Utils]] officially delivered. 
	- Next Steps: put on pipeline
	- Discuss with Arquitectura.
- Journal new prod incidence with lost of data.
	- Big Data admins can't see anything on the cluster or traces
	- All point to a App problem
	- Big Data Admins will check broker logs of the incidence time and comeback to us


# 2022-05-05 10:30
##### status: #meeting_note
##### Tags:

### Client:
[[Santander]]
### Topic:
Flume replacement by Syslog use case 
### Attendees:
* [[Fernando Rojas]]
* [[Oscar Gomez]]
### Notes:

![[{{Santander}} Syslog_usecase_diagram.png]]

![[{{Santander}} Syslog_event_example.png]]

> [!danger] Concerns
>  This piece need to be on HA mode so we need at least to intances. Since Syslog connector can't have more than a task (recommendation is deploy ir on standalone mode) how we can do it on a "standard cluster":
>   > [!question]
>   > Can we deploy more than a connector in the same distribute cluster (with 1 max task configured) if so there is any way to be sure that will be deployed on different workers?. 
>   > Can we have kind of sticky call to that worker (client side)?

> [!info] Volumetry
> 250k events/day

> [!question] Suggestion
> Deploy it on a K8s namespace wit CFK as stand alone pods and put a service wrapping them.

# 2022-05-05 11:18
##### status: #meeting_note
##### Tags:

### Client:
[[Santander]]
### Topic:
Kafka Test Utils lifecycle process
### Attendees:
* [[Abel Alvarez Fernandez]]
* [[Jose Alberto Rollon]]
* [[Lucia Lopez]]
* [[Daniel Villanueva]]

### Notes:

In memory server and [[Kafka Test Utils]] must be on separate artifacts (with mutual dependency each other)

2 options for the deployment:

1. Architecture Team will be responsible of the In memory server, will grab it from my repo and get into theirs. [[Jose Alberto Rollon]] will be in charge of Kafka test utils part with its own pipe
2. Architecture responsible of both of them and the pipeline

No problems with the original versioning proposal

Next Steps:

- Upload the last version to [[Jose Alberto Rollon]]
- [[Daniel Villanueva]] will check with his team the option 2 and provide repositories for both of the libraries.

# 2022-05-05 18:41
##### status: #meeting_note
##### Tags:

### Client:
[[Santander]]
### Topic:
PTI Incident Review
### Attendees:
* [[Abel Alvarez Fernandez]]
* [[Miguel Angel Garcia De La Cruz]]
* [[Fernando Rojas]]
* Journal Team

### Notes:
- Degradation of performance with transactionality on the micros tested on local is about a 5% (pending to test in PRE env)
> [!question] Next Steps
> Put transactional code on all the chain and deploy in PROD
> Next monday 18h -> functional and resilency test

- Lost of msgs in the past days:
	- No evidence of platform failure, we only can see a few peeks on the out throughput (all point to GDO) but still didn't explain the errors
	- Taking a look of the first APP point is a very messy spring boot app that is running a KStreams inside (plain Kstream library) with heavy processing on the consume (calls to ORACLE, Mongo even DB2) (principal suspect for the error)



